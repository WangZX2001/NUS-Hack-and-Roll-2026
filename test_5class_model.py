#!/usr/bin/env python3
"""
Test the 5-class model that was actually trained.
"""

from ultralytics import YOLO
from pathlib import Path
import random

def test_5class_model():
    """Test the 5-class model with correct path."""
    
    # Correct path where the model was actually saved
    model_path = "runs/classify/runs/classify/5class_model/weights/best.pt"
    
    if not Path(model_path).exists():
        print(f"âŒ Model not found at {model_path}")
        return False
    
    print(f"âœ… Found 5-class model at: {model_path}")
    
    try:
        model = YOLO(model_path)
        print(f"ğŸ¤– Model loaded successfully")
        print(f"ğŸ“Š Model classes: {model.names}")
        print(f"ğŸ”¢ Number of classes: {len(model.names)}")
        
        # Test on validation images
        val_dir = Path("dataset_5class/val")
        if not val_dir.exists():
            print("âš ï¸  Validation dataset not found")
            return True  # Model loads, just no test data
        
        classes = ['paper', 'metal', 'plastic', 'glass', 'trash']
        overall_results = {}
        
        print(f"\nğŸ§ª Testing model on validation data:")
        print("=" * 50)
        
        for class_name in classes:
            class_dir = val_dir / class_name
            if not class_dir.exists():
                print(f"âš ï¸  {class_name} directory not found")
                continue
                
            image_files = list(class_dir.glob('*.jpg'))[:8]  # Test 8 per class
            
            if not image_files:
                print(f"âš ï¸  No images in {class_name}")
                continue
            
            print(f"\nğŸ” Testing {class_name} ({len(image_files)} images):")
            correct = 0
            confidences = []
            
            for img_path in image_files:
                try:
                    results = model(img_path, verbose=False)
                    if results and len(results) > 0:
                        pred_class = results[0].names[results[0].probs.top1]
                        confidence = results[0].probs.top1conf.item()
                        confidences.append(confidence)
                        
                        status = "âœ…" if pred_class == class_name else "âŒ"
                        if pred_class == class_name:
                            correct += 1
                        
                        print(f"   {status} {img_path.name}: {pred_class} ({confidence:.3f})")
                except Exception as e:
                    print(f"   âŒ Error: {e}")
            
            accuracy = correct / len(image_files) * 100 if image_files else 0
            avg_confidence = sum(confidences) / len(confidences) if confidences else 0
            
            overall_results[class_name] = {
                'accuracy': accuracy,
                'confidence': avg_confidence,
                'tested': len(image_files),
                'correct': correct
            }
            
            print(f"   ğŸ“Š {class_name} accuracy: {accuracy:.1f}% (avg conf: {avg_confidence:.3f})")
        
        # Overall summary
        if overall_results:
            total_correct = sum(r['correct'] for r in overall_results.values())
            total_tested = sum(r['tested'] for r in overall_results.values())
            overall_accuracy = total_correct / total_tested * 100 if total_tested > 0 else 0
            
            print(f"\nğŸ“ˆ OVERALL RESULTS:")
            print(f"   Total accuracy: {overall_accuracy:.1f}% ({total_correct}/{total_tested})")
            
            # Show per-class results
            for class_name, results in overall_results.items():
                print(f"   {class_name:>7}: {results['accuracy']:>5.1f}%")
            
            # Check if glass is working better
            if 'glass' in overall_results:
                glass_acc = overall_results['glass']['accuracy']
                print(f"\nğŸ¶ Glass Classification:")
                if glass_acc >= 80:
                    print(f"   âœ… Excellent glass detection: {glass_acc:.1f}%")
                elif glass_acc >= 60:
                    print(f"   âœ… Good glass detection: {glass_acc:.1f}%")
                else:
                    print(f"   âš ï¸  Glass detection needs improvement: {glass_acc:.1f}%")
        
        return True
        
    except Exception as e:
        print(f"âŒ Error loading model: {e}")
        return False

def update_webapp_paths():
    """Update webapp to use correct model path."""
    print(f"\nğŸ”§ WEBAPP UPDATE:")
    print("=" * 50)
    
    correct_path = "runs/classify/runs/classify/5class_model/weights/best.pt"
    
    print(f"âœ… Your 5-class model is at:")
    print(f"   {correct_path}")
    
    print(f"\nğŸ“ Update webapp_5class.py:")
    print(f"   Change the model_paths list to:")
    print(f'   model_paths = [')
    print(f'       "{correct_path}",')
    print(f'       "runs/classify/train2/weights/best.pt"  # fallback')
    print(f'   ]')
    
    print(f"\nğŸš€ Then run:")
    print(f"   python webapp_5class.py")

def main():
    print("ğŸ” 5-CLASS MODEL TESTER")
    print("=" * 50)
    
    success = test_5class_model()
    
    if success:
        update_webapp_paths()
        
        print(f"\nğŸ¯ SUMMARY:")
        print(f"âœ… 5-class model trained successfully")
        print(f"âœ… Model can be loaded and used")
        print(f"ğŸ“ Model location: runs/classify/runs/classify/5class_model/weights/best.pt")
        print(f"\nğŸŒ Next: Update webapp_5class.py with correct path and test!")
    else:
        print(f"\nâŒ Model testing failed")

if __name__ == "__main__":
    main()